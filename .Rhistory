funsense<-sensemakr(lm_fun,treatment = "tmax.diff")
funsense<-sensemakr(lm_fun,treatment = "tmax.diff",benchmark_covariates = "prcp.diff")
remove.packages('sensemakr')
install.packages('sensemakr')
library(sensemakr)
knitr::opts_chunk$set(echo = TRUE)
library(sensemakr)
install.packages('sensemakr')
library(sensemakr)
lm_fun<-lm(any_ment.diff ~ tmax.diff + prcp.diff, data=diff)
funsense<-sensemakr(lm_fun,treatment = "tmax.diff",benchmark_covariates = "prcp.diff")
funsense<-sensemakr(lm_fun,treatment = "tmax.diff")
class(lm_fun)
library(sensemakr)
covar <- c("prcp.diff","trange.diff")
sense <- sensemakr(ld_lm, data=diff, treatment = "tmax.diff")
knitr::kable(sense$sensitivity_stats)
sense <- sensemakr(ld_lm, data=diff, treatment = "tmax.diff",benchmark_covariates = as.character(prcp.diff))
sense <- sensemakr(ld_lm, data=diff, treatment = "tmax.diff",benchmark_covariates = as.character('prcp.diff'))
class(as.character('prcp.diff'))
sense <- sensemakr(ld_lm, data=diff, treatment = "tmax.diff")
knitr::kable(sense$sensitivity_stats)
robustness_value(ld_lm, covariates = "tmax.diff")
plot(sense,type="extreme")
plot(sense)
c117_vote<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/S117_votes (1).csv")
library(tidyverse)
library(dplyr)
library(kableExtra)
library(knitr)
library(foreign)
library(stargazer)
library(lmtest)
library(sandwich)
library(estimatr)
library(clubSandwich)
library(ggplot2)
getwd()
members<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/members.csv")
c117_vote<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/S117_votes (1).csv")
members<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/members.csv")
ideol<-read_csv("./ideol.csv")
nodes<-c117_vote %>% distinct(icpsr) %>% rowid_to_column("id")
nodes<-merge(nodes,ideol,by='icpsr')
nodes<-nodes[-c(91,82),-2]
mat<-matrix(,nrow = 100, ncol = 100)
for (i in 1:100){
#iteratre through i congresspeople
for(j in 1:100){
#iterate j congresspeople
tally<-0
#votes in common
newdat<-subset(x=c117_vote,
icpsr==as.numeric(nodes[i,1])|icpsr==as.numeric(nodes[j,1]))
#subset only relevant i, j votes
#go through each rollcall vote
for(n in unique(newdat$rollnumber)){
#conditionally add one to tally of samevotes, condition:i and j voted the same
if(length(unique(newdat$cast_code[newdat$rollnumber==n]))==1) tally<-tally+1
}
#put ith jth matrix spot as percentage: same votes/total votes
mat[i,j]<-as.double(tally/length(unique(newdat$rollnumber)))
}
}
ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[3,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[3])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[3])+geom_smooth(color="dark green")+ylim(0,100)
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
plots <- list()  # new empty list
p1<-ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[1,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[1])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[1])+geom_smooth(color="dark green")+ylim(0,100)
p2<-ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[2,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[2])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[2])+geom_smooth(color="dark green")+ylim(0,100)
p3<-ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[3,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[3])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[3])+geom_smooth(color="dark green")+ylim(0,100)
p4<-ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[4,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[4])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[4])+geom_smooth(color="dark green")+ylim(0,100)
p5<-ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[5,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[5])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[5])+geom_smooth(color="dark green")+ylim(0,100)
p6<-ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[80,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[80])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[80])+geom_smooth(color="dark green")+ylim(0,100)
multiplot(p1,p2,p3,p4,p5,p6, cols = 2)
ggplot(as.data.frame(mat),aes(x=nodes$nominate_dim1,y=mat[3,]*100))+geom_point()+geom_vline(xintercept=nodes$nominate_dim1[3])+
xlab("dw nominate")+ylab("% identical vote record")+labs(subtitle=nodes$bioname[3])+geom_smooth(color="dark green")+ylim(0,100)
mat<-matrix(,nrow = 100, ncol = 100)
for (i in 1:100){
#iteratre through i congresspeople
for(j in 1:100){
#iterate j congresspeople
tally<-0
#votes in common
newdat<-subset(x=c117_vote,
icpsr==as.numeric(nodes[i,1])|icpsr==as.numeric(nodes[j,1]))
#subset only relevant i, j votes
#go through each rollcall vote
for(n in unique(newdat$rollnumber)){
#conditionally add one to tally of samevotes, condition:i and j voted the same
if(length(unique(newdat$cast_code[newdat$rollnumber==n]))==1) tally<-tally+1
}
#put ith jth matrix spot as percentage: same votes/total votes
mat[i,j]<-as.double(tally/length(unique(newdat$rollnumber)))
}
}
c117_vote<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/S117_votes (1).csv")
members<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/members.csv")
ideol<-read_csv("./ideol.csv")
nodes<-c117_vote %>% distinct(icpsr) %>% rowid_to_column("id")
nodes<-merge(nodes,ideol,by='icpsr')
nodes<-nodes[-c(91,82),-2]
View(nodes)
c117_vote<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/S117_votes (1).csv")
nodes<-c117_vote %>% distinct(icpsr) %>% rowid_to_column("id")
ideol<-read_csv("./ideol.csv")
nodes<-c117_vote %>% distinct(icpsr) %>% rowid_to_column("id")
View(nodes)
nodes<-nodes[-c(91,82),-2]
c117_vote<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/S117_votes (1).csv")
members<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/members.csv")
ideol<-read_csv("./ideol.csv")
nodes<-c117_vote %>% distinct(icpsr) %>% rowid_to_column("id")
nodes<-merge(nodes,ideol,by='icpsr')
nodes<-nodes[-c(91,82),]
mat<-matrix(,nrow = 100, ncol = 100)
for (i in 1:100){
#iteratre through i congresspeople
for(j in 1:100){
#iterate j congresspeople
tally<-0
#votes in common
newdat<-subset(x=c117_vote,
icpsr==as.numeric(nodes[i,1])|icpsr==as.numeric(nodes[j,1]))
#subset only relevant i, j votes
#go through each rollcall vote
for(n in unique(newdat$rollnumber)){
#conditionally add one to tally of samevotes, condition:i and j voted the same
if(length(unique(newdat$cast_code[newdat$rollnumber==n]))==1) tally<-tally+1
}
#put ith jth matrix spot as percentage: same votes/total votes
mat[i,j]<-as.double(tally/length(unique(newdat$rollnumber)))
}
}
for (i in 1:100){
#iteratre through i congresspeople
for(j in 1:100){
#iterate j congresspeople
tally<-0
#votes in common
newdat<-subset(x=c117_vote,
icpsr==as.numeric(nodes[i,1])|icpsr==as.numeric(nodes[j,1]))
#subset only relevant i, j votes
#go through each rollcall vote
for(n in unique(newdat$rollnumber)){
#conditionally add one to tally of samevotes, condition:i and j voted the same
if(length(unique(newdat$cast_code[newdat$rollnumber==n]))==1) tally<-tally+1
}
#put ith jth matrix spot as percentage: same votes/total votes
mat[i,j]<-as.double(tally/length(unique(newdat$rollnumber)))
}
}
rary(tidyverse)
library(dplyr)
library(kableExtra)
library(knitr)
library(foreign)
library(stargazer)
library(lmtest)
library(sandwich)
library(estimatr)
library(clubSandwich)
library(ggplot2)
getwd()
c117_vote<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/S117_votes (1).csv")
members<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/members.csv")
ideol<-read_csv("./ideol.csv")
nodes<-c117_vote %>% distinct(icpsr) %>% rowid_to_column("id")
nodes<-merge(nodes,ideol,by='icpsr')
nodes<-nodes[-c(91,82),]
mat<-matrix(,nrow = 100, ncol = 100)
for (i in 1:100){
#iteratre through i congresspeople
for(j in 1:100){
#iterate j congresspeople
tally<-0
#votes in common
newdat<-subset(x=c117_vote,
icpsr==as.numeric(nodes[i,1])|icpsr==as.numeric(nodes[j,1]))
#subset only relevant i, j votes
#go through each rollcall vote
for(n in unique(newdat$rollnumber)){
#conditionally add one to tally of samevotes, condition:i and j voted the same
if(length(unique(newdat$cast_code[newdat$rollnumber==n]))==1) tally<-tally+1
}
#put ith jth matrix spot as percentage: same votes/total votes
mat[i,j]<-as.double(tally/length(unique(newdat$rollnumber)))
}
}
View(c117_vote)
newdat<-subset(x=c117_vote,
icpsr==as.numeric(nodes[1,1])|icpsr==as.numeric(nodes[10,1]))
newdat<-subset(x=c117_vote,
icpsr==as.numeric(nodes[1,1])|icpsr==as.numeric(nodes[10,1]))
c117_vote<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/S117_votes (1).csv")
members<-read_csv("/Users/gpstraus/Desktop/ind. research/network analysis/members.csv")
ideol<-read_csv("./ideol.csv")
c117_vote<-read_csv("./network analysis/S117_votes (1).csv")
c117_vote<-read_csv("./network analysis/S117_votes (1).csv")
install.packages(c("coda","mvtnorm","devtools","dagitty"))
library(devtools)
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
library(tidyverse)
ways <- c( 0 , 3 , 8 , 9 , 0 )
ways/sum(ways)
dbinom(6,9,.5)
dbinom(6,9,.3)
p_grid<-seq(from = 0, to = 1, length.out=20)
view(p_grid)
prior<-rep(1,20)
likelihood<-dbinom(6,9,prob = p_grid)
unstd.posterior<-likelihood*prior
posterior<-unstd.posterior/sum(unstd.posterior)
view(posterior)
plot( p_grid , posterior , type="b" ,
xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
globe.qa <- quap(
alist(
W ~ dbinom( W+L ,p) ,  # binomial likelihood
p ~ dunif(0,1)     # uniform prior
) ,
data=list(W=6,L=3) )
globe.qa
summary(globe.qa)# display summary of quadratic approximation
precis( globe.qa )
?precis
?dbeta
W <- 6
L <- 3
curve( dbeta( x , W+1 , L+1 ) , from=0 , to=1 )
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
?alist
n_samples <- 1000
p <- rep( NA , n_samples )
p[1] <- 0.5
W <- 6
L <- 3
for ( i in 2:n_samples ) {
p_new <- rnorm( 1 , p[i-1] , 0.1 )
if ( p_new < 0 ) p_new <- abs( p_new )
if ( p_new > 1 ) p_new <- 2 - p_new
q0 <- dbinom( W , W+L , p[i-1] )
q1 <- dbinom( W , W+L , p_new )
p[i] <- ifelse( runif(1) < q1/q0 , p_new , p[i-1] )
}
## R code 2.9
dens( p , xlim=c(0,1) )
curve( dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE )
library(targets)
source("functions.R")
library(targets)
source("functions.R")
library(targets)
source("functions.R")
install.packages('vitae')
install.packages("sf")
dat<-sf::st_read(/Users/gpstraus/Desktop/fire20_1.gdb/a000000af.gdbtable)
dat<-sf::st_read("/Users/gpstraus/Desktop/fire20_1.gdb/a000000af.gdbtable")
View(dat)
View(dat[[18]][[2]])
head(dat)
dat_2020<-dat %>% filter(YEAR == 2020)
dat_2020<-dplyr::filter(dat,YEAR == 2020)
dat_2020<-dplyr::filter(dat,YEAR_ == 2020)
View(dat_2020)
class(dat$YEAR_)
library(dplyr)
dat %>% mutate(year = as.numeric(YEAR_))
dat<-dat %>% mutate(year = as.numeric(YEAR_))
summary(dat$year)
ti<-head(dat)
View(ti)
counties<-sf::st_read("/Users/gpstraus/Desktop/cnty19_1.gdb/a00000009.gdbtable")
View(counties)
gp<-counties %>% group_by(COUNTY_CODE)
View(gp)
gp<-gp %>% slice(.1)
gp<-sample_frac(gp,.1)
View(gp)
2020_dat<-read.csv("/Users/gpstraus/Dropbox/california-fire-tracking/Data/fire_track_2020.csv")
2020-dat<-read.csv("/Users/gpstraus/Dropbox/california-fire-tracking/Data/fire_track_2020.csv")
dat2<-read.csv("/Users/gpstraus/Dropbox/california-fire-tracking/Data/fire_track_2020.csv")
View(dat2)
dat2_org<-dat %>% group_by(Counties)
colnames(dat2)
dat2 %>% group_by(Counties)
dat2_org %>% group_by(Counties)
dat2-org<-dat2 %>% group_by(Counties)
dat2org<-dat2 %>% group_by(Counties)
View(dat2org)
View(dat2)
by_cyl <- mtcars %>% group_by(cyl)
View(by_cyl)
mtcars
view(mtcars)
View(mtcars)
#load data
dat<-read.csv("/Data/master_ca_fire.csv")
#load data
dat<-read.csv("Data/master_ca_fire.csv")
#load data
dat<-read.csv("/Data/master_ca_fire.csv")
#load data
dat<-read.csv("/Data/master_ca_fire.csv")
#load data
dat<-read.csv("./Data/master_ca_fire.csv")
getwd()
getwd()
setwd("/Users/gpstraus/Dropbox/california-fire-tracking")
#load data
dat<-read.csv("/Data/master_ca_fire.csv")
#load data
dat<-read.csv("Data/master_ca_fire.csv")
colnames(dat)
dat %>% group_by(Counties) %>% summarise(
n = n(),
acres_burned = sum(AcresBurned)
)
summary_stats<-dat %>% group_by(Counties) %>% summarise(
n = n(),
acres_burned = sum(AcresBurned)
)
View(summary_stats)
View(dat)
dat %>% filter(Counties == Alameda)
dat %>% filter(Counties == "Alameda")
Alameda<-dat %>% filter(Counties == "Alameda")
sum(Alameda$AcresBurned)
summary_stats<-dat %>% filter(Counties != c("State of Nevada","State of Oregon"))
summary_stats<-dat %>% filter(Counties != c("State of Nevada","State of Oregon")) %>%
group_by(Counties) %>% summarise(
n = n(),
acres_burned = sum(AcresBurned)
)
summary_stats<-dat %>% filter(Counties !== c("State of Nevada","State of Oregon")) %>%
group_by(Counties) %>% summarise(
n = n(),
acres_burned = sum(AcresBurned)
)
#load data
dat<-read.csv("Data/master_ca_fire.csv")
#load data
dat<-read.csv("Data/master_ca_fire.csv")
summary_stats<-dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
filter(Counties == "San Francisco")
View(summary_stats)
#load data
dat<-read.csv("Data/master_ca_fire.csv")
summary_stats<-dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
Alameda<-dat %>% filter(Counties == "Alameda")
#load data
dat<-read.csv("Data/master_ca_fire.csv")
summary_stats<-dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
Alameda<-dat %>% filter(Counties == "Alameda")
#load data
getwd()
#load data
library(tidyverse)
dat<-read.csv("Data/master_ca_fire.csv")
summary_stats<-dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
Alameda<-dat %>% filter(Counties == "Alameda")
colnames("Dat")
colnames("dat")
class(dat)
dat<-read.csv("Data/master_ca_fire.csv")
summary_stats <- dat %>% group_by(Counties) %>% summarise(
n = n(),
acres_burned = sum(AcresBurned))
View(summary_stats)
summary_stats <- dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
subset(Counties != c("State of Oregon","State of Nevada"))
summary_stats <- dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
subset(Counties != "State of Oregon")
summary_stats <- dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned))
summary_stats <- dat %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
filter(Counties != "State of Oregon" & Counties != "State of Nevada")
View(summary_stats)
fresno<-dat %>% filter(Counties == "Fresno")
View(fresno)
View(dat)
View(dat)
summary_stats <- dat %>% drop_na(AcresBurned) %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
filter(Counties != "State of Oregon" & Counties != "State of Nevada")
View(summary_stats)
delnorte<-dat %>% filter(Counties == "Del Norte")
View(delnorte)
sum(delnorte$AcresBurned)
View(dat)
#load data
library(tidyverse)
dat<-read.csv("Data/master_ca_fire.csv")
summary_stats <- dat %>% drop_na(AcresBurned) %>%
group_by(Counties) %>%
summarise(
n = n(),
acres_burned = sum(AcresBurned)) %>%
filter(Counties != "State of Oregon" & Counties != "State of Nevada")
View(summary_stats)
2+2
getwd()
library(rvest)
page<-read_html("https://moodle2.sscnet.ucla.edu/mod/resource/index.php?id=17540")
links<-page %>% html_attr("href")
list<-page %>% html_nodes("a") %>% html_attr("href")
view(list)
view(list)
view(data.frame(list))
View(data.frame(list))
write.csv(data.frame(list),file = "output.csv")
page<-read_html("https://moodle2.sscnet.ucla.edu/mod/resource/index.php?id=17540")
list<-page %>% html_nodes("a") %>% html_attr("href")
write.csv(data.frame(list),file = "output.csv")
page<-read_html("https://moodle2.sscnet.ucla.edu/mod/resource/index.php?id=17540")
list<-page %>% html_nodes("td") %>% html_attr("href")
write.csv(data.frame(list),file = "output.csv")
page<-read_html("https://moodle2.sscnet.ucla.edu/mod/resource/index.php?id=17540")
list<-page %>% html_nodes("td") %>% html_attr("href")
view(data.frame(list))
View(data.frame(list))
list<-page %>% html_nodes("a") %>% html_attr("href")
View(data.frame(list))
page %>% html_nodes("td")
a
page %>% html_nodes("td") %>% html_nodes("cell c1")
page %>% html_nodes("td") %>% html_nodes("class")
page %>% html_nodes("td") %>% html_nodes("class")
page %>% html_nodes("td")
page %>% html_nodes("td") %>% html_nodes("[class='c1']")
page %>% html_nodes("td") %>% html_nodes("[class='cell c1']")
page %>% html_nodes("[class='cell c1']")
length(page %>% html_nodes("[class='cell c1']"))
page %>% html_nodes("[class='cell c1']") %>% html_attr("href")
page %>% html_nodes("[class='cell c1']") %>% html_attr("href")
page %>% html_nodes("[class='cell c1']")
page %>% html_nodes("[class='cell c1']") %>% html_attr("href")
page %>% html_nodes("[class='cell c1']") %>% html_attr("href")
page %>% html_nodes("[class='cell c1']")
page %>% html_nodes("a")
length(page %>% html_nodes("a"))
page %>% html_nodes("a") %>% html_attr("href")
